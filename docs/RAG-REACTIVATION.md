# üîÑ RAG - Guide de R√©activation

## üö´ √âtat Actuel : D√âSACTIV√â

Le syst√®me RAG est temporairement d√©sactiv√© car le quota gratuit de l'API Gemini Embeddings a √©t√© d√©pass√©.

**Le chat fonctionne normalement sans RAG** - c'est juste la m√©moire long-terme qui est d√©sactiv√©e.

---

## üìã Options pour R√©activer le RAG

### Option 1: OpenAI (Recommand√© pour Production) üí∞

**Co√ªt**: ~$0.0001 par message (tr√®s peu cher)  
**Dimensions**: 1536D  
**Qualit√©**: Excellente

#### √âtapes :

1. **Cr√©er un compte OpenAI** : https://platform.openai.com/signup
2. **Ajouter une carte bancaire** : Settings > Billing
3. **Cr√©er une API Key** : https://platform.openai.com/api-keys
4. **Ajouter dans `.env`** :
   ```env
   EMBEDDING_PROVIDER=OPENAI
   OPENAI_API_KEY=sk-xxxxxxxxxxxx
   ```
5. **Modifier la table Supabase** (change 768D ‚Üí 1536D) :
   ```sql
   -- Supabase SQL Editor
   ALTER TABLE conversations ALTER COLUMN embedding TYPE vector(1536);
   DROP INDEX idx_conversations_embedding;
   CREATE INDEX idx_conversations_embedding ON conversations 
     USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
   
   -- Modifier la fonction RPC
   CREATE OR REPLACE FUNCTION match_conversations(
     query_embedding vector(1536), -- Change 768 ‚Üí 1536
     match_threshold float DEFAULT 0.7,
     match_count int DEFAULT 5
   )
   RETURNS TABLE (
     id UUID,
     user_id TEXT,
     user_query TEXT,
     vera_response TEXT,
     metadata JSONB,
     created_at TIMESTAMPTZ,
     similarity FLOAT
   )
   LANGUAGE plpgsql
   AS $$
   BEGIN
     RETURN QUERY
     SELECT
       c.id,
       c.user_id,
       c.user_query,
       c.vera_response,
       c.metadata,
       c.created_at,
       1 - (c.embedding <=> query_embedding) AS similarity
     FROM conversations c
     WHERE 1 - (c.embedding <=> query_embedding) > match_threshold
     ORDER BY c.embedding <=> query_embedding
     LIMIT match_count;
   END;
   $$;
   ```

6. **D√©commenter le code RAG dans `vera.service.js`** :
   - Ligne ~370 : Recherche de m√©moire
   - Ligne ~600 : Stockage de conversation

7. **Red√©marrer le serveur** :
   ```bash
   cd vera-back
   npm run api
   ```

---

### Option 2: Gemini (Gratuit) üÜì

**Co√ªt**: Gratuit (avec quotas)  
**Dimensions**: 768D  
**Qualit√©**: Bonne  
**Limite**: 1500 requ√™tes/jour

#### √âtapes :

1. **Cr√©er un nouveau projet Google Cloud**
2. **Activer Gemini API**
3. **Cr√©er une nouvelle API Key**
4. **Ajouter dans `.env`** :
   ```env
   EMBEDDING_PROVIDER=GEMINI
   GEMINI_API_KEY=AIzaSyxxxxxxxxxxxx  # NOUVELLE CL√â
   ```
5. **La table Supabase est d√©j√† configur√©e pour 768D** ‚úÖ
6. **D√©commenter le code RAG dans `vera.service.js`**
7. **Red√©marrer le serveur**

---

### Option 3: HuggingFace (Gratuit + Self-Hosted) ü§ó

**Co√ªt**: Gratuit (API) ou Self-hosted  
**Dimensions**: 384D ou 768D selon mod√®le  
**Qualit√©**: Variable

#### Mod√®les recommand√©s :
- `sentence-transformers/all-MiniLM-L6-v2` (384D, rapide)
- `sentence-transformers/all-mpnet-base-v2` (768D, meilleur)

#### √âtapes :

1. **Installer transformers** :
   ```bash
   cd vera-back
   npm install @huggingface/inference
   ```

2. **Cr√©er `app/services/huggingface-embedding.service.js`** :
   ```javascript
   const { HfInference } = require('@huggingface/inference');
   
   class HuggingFaceEmbeddingService {
     constructor() {
       this.hf = new HfInference(process.env.HUGGINGFACE_API_KEY);
       this.model = 'sentence-transformers/all-mpnet-base-v2';
     }
     
     async generateEmbedding(text) {
       const result = await this.hf.featureExtraction({
         model: this.model,
         inputs: text
       });
       return Array.from(result);
     }
   }
   
   module.exports = new HuggingFaceEmbeddingService();
   ```

3. **Modifier `embedding.service.js`** pour utiliser HuggingFace

4. **Cr√©er une API key gratuite** : https://huggingface.co/settings/tokens

5. **Ajouter dans `.env`** :
   ```env
   EMBEDDING_PROVIDER=HUGGINGFACE
   HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxx
   ```

---

## üîì D√©commenter le Code RAG

Une fois le provider d'embeddings configur√©, **d√©commenter ces blocs** dans `vera-back/app/services/vera.service.js` :

### Bloc 1: Recherche de M√©moire (~ligne 370)

```javascript
// D√©commenter de la ligne "try {" jusqu'√† "} catch (ragError) {"
try {
    const queryEmbedding = await embeddingService.generateEmbedding(message);
    const userId = conversationId || `web-user-${Date.now()}`;
    similarConversations = await vectorStoreService.searchSimilarConversations(
        queryEmbedding,
        null,
        3,
        0.75
    );
    
    if (similarConversations.length > 0) {
        console.log(`üß† RAG: ${similarConversations.length} conversations similaires trouv√©es`);
        ragContext = '\n\nüíæ M√âMOIRE (conversations similaires pass√©es):\n';
        similarConversations.forEach((conv, i) => {
            ragContext += `\n[${i+1}] Similarit√©: ${(conv.similarity * 100).toFixed(1)}%\n`;
            ragContext += `Q: ${conv.user_query}\n`;
            ragContext += `R: ${conv.vera_response.substring(0, 200)}...\n`;
        });
        ragContext += '\n‚ö†Ô∏è Utilise ces conversations pass√©es pour enrichir ta r√©ponse si pertinent.\n';
    }
} catch (ragError) {
    console.warn('‚ö†Ô∏è RAG non disponible:', ragError.message);
}
```

### Bloc 2: Stockage de Conversation (~ligne 600)

```javascript
// D√©commenter de la ligne "try {" jusqu'√† la fin du bloc
try {
    const userId = conversationId || `web-user-${Date.now()}`;
    const veraResponseText = typeof result === 'string' ? result : 
                            result.summary || result.message || JSON.stringify(result);
    const conversationText = embeddingService.prepareConversationText(message, veraResponseText);
    const conversationEmbedding = await embeddingService.generateEmbedding(conversationText);
    
    await vectorStoreService.storeConversation(
        userId,
        message,
        veraResponseText,
        conversationEmbedding,
        {
            media_urls: mediaUrls,
            has_files: !!(imageFile || videoFile),
            platform_videos: extractedMedias.length,
            similar_conversations_used: similarConversations.length
        }
    );
    
    console.log('‚úÖ Conversation stock√©e dans la m√©moire RAG');
} catch (storageError) {
    console.warn('‚ö†Ô∏è Stockage RAG √©chou√©:', storageError.message);
}
```

---

## ‚úÖ V√©rifier que √ßa Fonctionne

Apr√®s r√©activation, tu devrais voir dans les logs :

```
ü§ñ Embedding Service: OpenAI (1536D)
[API] Serveur d√©marr√© sur http://localhost:3000
...
üß† RAG: 3 conversations similaires trouv√©es
‚úÖ Conversation stock√©e dans la m√©moire RAG
```

---

## üìä Co√ªts Comparatifs

| Provider | Co√ªt / 1K requ√™tes | Co√ªt / mois (100 msg/jour) |
|----------|-------------------|---------------------------|
| **OpenAI** | $0.10 | ~$0.60/mois |
| **Gemini** | Gratuit | $0 (jusqu'√† 1500/jour) |
| **HuggingFace** | Gratuit | $0 (rate limited) |

üí° **Recommandation** : OpenAI pour production (co√ªt n√©gligeable), Gemini pour dev/test

---

## üÜò Probl√®mes Fr√©quents

### "OPENAI_API_KEY non d√©finie"
‚Üí V√©rifie que `.env` contient bien la cl√© et que `EMBEDDING_PROVIDER=OPENAI`

### "dimension mismatch"
‚Üí La table Supabase est en 768D mais OpenAI produit 1536D. Ex√©cute le script SQL ci-dessus.

### "quota exceeded"
‚Üí Gemini : Attendre 24h ou changer de provider  
‚Üí OpenAI : Ajouter du cr√©dit sur le compte

### "Cannot read property 'values' of undefined"
‚Üí Gemini : V√©rifie que la cl√© API est valide  
‚Üí Mod√®le embedding-001 existe bien

---

## üìö Documentation Compl√®te

Voir `docs/RAG-MEMORY.md` pour :
- Architecture compl√®te
- API endpoints
- Cas d'usage
- Maintenance
- Troubleshooting avanc√©

---

**Cr√©√© le**: 3 D√©cembre 2025  
**Derni√®re MAJ**: 3 D√©cembre 2025  
**Status**: RAG D√âSACTIV√â (quota embeddings)  
