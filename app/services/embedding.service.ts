import { GoogleGenerativeAI } from '@google/generative-ai';
import axios from 'axios';

type EmbeddingProvider = 'OPENAI' | 'GEMINI';

class EmbeddingService {
  private provider: EmbeddingProvider;
  private disabled: boolean = false;
  private dimensions: number;
  private genAI?: GoogleGenerativeAI;
  private model?: any;

  constructor() {
    // D√©terminer le provider (OPENAI ou GEMINI)
    this.provider = (process.env.EMBEDDING_PROVIDER as EmbeddingProvider) || 'OPENAI';
    
    if (this.provider === 'OPENAI') {
      if (!process.env.OPENAI_API_KEY) {
        console.warn('‚ö†Ô∏è OPENAI_API_KEY non d√©finie - Service d\'embedding d√©sactiv√©');
        this.disabled = true;
        this.dimensions = 0;
        return;
      }
      this.dimensions = 1536; // OpenAI text-embedding-ada-002
      console.log('ü§ñ Embedding Service: OpenAI (1536D)');
    } else if (this.provider === 'GEMINI') {
      if (!process.env.GEMINI_API_KEY) {
        console.warn('‚ö†Ô∏è GEMINI_API_KEY non d√©finie - Service d\'embedding d√©sactiv√©');
        this.disabled = true;
        this.dimensions = 0;
        return;
      }
      this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
      this.model = this.genAI.getGenerativeModel({ model: 'embedding-001' });
      this.dimensions = 768; // Gemini embedding-001
      console.log('ü§ñ Embedding Service: Gemini (768D)');
    } else {
      throw new Error(`Provider inconnu: ${this.provider}. Utiliser OPENAI ou GEMINI`);
    }
  }

  /**
   * G√©n√®re un embedding vectoriel pour un texte donn√©
   * @param text - Le texte √† convertir en vecteur
   * @returns Vecteur d'embeddings (1536D pour OpenAI, 768D pour Gemini)
   */
  async generateEmbedding(text: string): Promise<number[]> {
    if (this.disabled) {
      console.warn('‚ö†Ô∏è Embedding Service d√©sactiv√© - Retour d\'un vecteur vide');
      return [];
    }

    if (!text || typeof text !== 'string') {
      throw new Error('Le texte doit √™tre une cha√Æne non vide');
    }

    try {
      if (this.provider === 'OPENAI') {
        return await this.generateOpenAIEmbedding(text);
      } else {
        return await this.generateGeminiEmbedding(text);
      }
    } catch (error: any) {
      console.error('Erreur g√©n√©ration embedding:', error.message);
      throw new Error(`√âchec g√©n√©ration embedding: ${error.message}`);
    }
  }

  /**
   * G√©n√®re un embedding avec OpenAI
   */
  private async generateOpenAIEmbedding(text: string): Promise<number[]> {
    const response = await axios.post(
      'https://api.openai.com/v1/embeddings',
      {
        model: 'text-embedding-ada-002',
        input: text
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    return response.data.data[0].embedding;
  }

  /**
   * G√©n√®re un embedding avec Gemini
   */
  private async generateGeminiEmbedding(text: string): Promise<number[]> {
    if (!this.model) {
      throw new Error('Mod√®le Gemini non initialis√©');
    }
    const result = await this.model.embedContent(text);
    return result.embedding.values;
  }

  /**
   * G√©n√®re des embeddings pour plusieurs textes en batch
   * @param texts - Tableau de textes
   * @returns Tableau de vecteurs
   */
  async generateEmbeddings(texts: string[]): Promise<number[][]> {
    if (!Array.isArray(texts)) {
      throw new Error('texts doit √™tre un tableau');
    }

    try {
      const embeddings = await Promise.all(
        texts.map(text => this.generateEmbedding(text))
      );
      return embeddings;
    } catch (error: any) {
      console.error('Erreur g√©n√©ration embeddings batch:', error.message);
      throw error;
    }
  }

  /**
   * Pr√©pare le texte d'une conversation pour l'embedding
   * @param userQuery - Question de l'utilisateur
   * @param veraResponse - R√©ponse de Vera
   * @returns Texte combin√© optimis√© pour l'embedding
   */
  prepareConversationText(userQuery: string, veraResponse: string): string {
    // Combine query + r√©ponse pour un embedding plus riche
    return `Question: ${userQuery}\n\nR√©ponse: ${veraResponse}`;
  }
}

// Export singleton
export default new EmbeddingService();
