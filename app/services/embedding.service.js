const { GoogleGenerativeAI } = require('@google/generative-ai');

class EmbeddingService {
  constructor() {
    // D√©terminer le provider (OPENAI ou GEMINI)
    this.provider = process.env.EMBEDDING_PROVIDER || 'OPENAI'; // D√©faut: OpenAI
    
    if (this.provider === 'OPENAI') {
      if (!process.env.OPENAI_API_KEY) {
        console.warn('‚ö†Ô∏è OPENAI_API_KEY non d√©finie - Service d\'embedding d√©sactiv√©');
        this.disabled = true;
        return;
      }
      this.dimensions = 1536; // OpenAI text-embedding-ada-002
      console.log('ü§ñ Embedding Service: OpenAI (1536D)');
    } else if (this.provider === 'GEMINI') {
      if (!process.env.GEMINI_API_KEY) {
        console.warn('‚ö†Ô∏è GEMINI_API_KEY non d√©finie - Service d\'embedding d√©sactiv√©');
        this.disabled = true;
        return;
      }
      this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
      this.model = this.genAI.getGenerativeModel({ model: 'embedding-001' });
      this.dimensions = 768; // Gemini embedding-001
      console.log('ü§ñ Embedding Service: Gemini (768D)');
    } else {
      throw new Error(`Provider inconnu: ${this.provider}. Utiliser OPENAI ou GEMINI`);
    }
  }

  /**
   * G√©n√®re un embedding vectoriel pour un texte donn√©
   * @param {string} text - Le texte √† convertir en vecteur
   * @returns {Promise<number[]>} - Vecteur d'embeddings (1536D pour OpenAI, 768D pour Gemini)
   */
  async generateEmbedding(text) {
    if (this.disabled) {
      console.warn('‚ö†Ô∏è Embedding Service d√©sactiv√© - Retour d\'un vecteur vide');
      return [];
    }

    if (!text || typeof text !== 'string') {
      throw new Error('Le texte doit √™tre une cha√Æne non vide');
    }

    try {
      if (this.provider === 'OPENAI') {
        return await this.generateOpenAIEmbedding(text);
      } else {
        return await this.generateGeminiEmbedding(text);
      }
    } catch (error) {
      console.error('Erreur g√©n√©ration embedding:', error.message);
      throw new Error(`√âchec g√©n√©ration embedding: ${error.message}`);
    }
  }

  /**
   * G√©n√®re un embedding avec OpenAI
   */
  async generateOpenAIEmbedding(text) {
    const axios = require('axios');
    
    const response = await axios.post(
      'https://api.openai.com/v1/embeddings',
      {
        model: 'text-embedding-ada-002',
        input: text
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    return response.data.data[0].embedding;
  }

  /**
   * G√©n√®re un embedding avec Gemini
   */
  async generateGeminiEmbedding(text) {
    const result = await this.model.embedContent(text);
    return result.embedding.values;
  }

  /**
   * G√©n√®re des embeddings pour plusieurs textes en batch
   * @param {string[]} texts - Tableau de textes
   * @returns {Promise<number[][]>} - Tableau de vecteurs
   */
  async generateEmbeddings(texts) {
    if (!Array.isArray(texts)) {
      throw new Error('texts doit √™tre un tableau');
    }

    try {
      const embeddings = await Promise.all(
        texts.map(text => this.generateEmbedding(text))
      );
      return embeddings;
    } catch (error) {
      console.error('Erreur g√©n√©ration embeddings batch:', error.message);
      throw error;
    }
  }

  /**
   * Pr√©pare le texte d'une conversation pour l'embedding
   * @param {string} userQuery - Question de l'utilisateur
   * @param {string} veraResponse - R√©ponse de Vera
   * @returns {string} - Texte combin√© optimis√© pour l'embedding
   */
  prepareConversationText(userQuery, veraResponse) {
    // Combine query + r√©ponse pour un embedding plus riche
    return `Question: ${userQuery}\n\nR√©ponse: ${veraResponse}`;
  }
}

// Export singleton
module.exports = new EmbeddingService();
